# Methodology

This research was conducted following strict operational security (OPSEC) protocols to ensure both researcher safety and compliance with applicable laws. The objective was to gather open-source intelligence (OSINT) from publicly accessible areas of the dark web without engaging in, facilitating, or promoting any illegal activity.  

## 1. Research Environment

- **Operating System:**  
  All dark web activity was conducted using **Tails OS** (The Amnesic Incognito Live System) to provide a secure, ephemeral environment. This ensured that no browsing history, downloaded files, or system modifications persisted after shutdown.

- **Network Anonymity Layers:**  
  - **VPN** connection established *before* initiating Tor sessions, creating a double-layered routing path (**VPN â†’ Tor**).  
  - **Tor Browser** used exclusively for dark web access, configured to the **Safest** security level.

## 2. Browser & Application Hardening

- **JavaScript Disabled:**  
  All browsing was performed with JavaScript disabled to mitigate tracking and exploitation risks from malicious scripts commonly found on onion sites.

- **No Plugins or External Media:**  
  Avoided the use of browser plugins, external fonts, or embedded multimedia to reduce fingerprinting risk.

- **No File Downloads:**  
  Downloading from unknown sources was strictly avoided unless the file was required for research and could be safely analyzed in an isolated sandbox environment.

## 3. Access Scope & Limitations

- **Publicly Accessible Content Only:**  
  The research did not involve bypassing authentication mechanisms, exploiting vulnerabilities, or accessing restricted systems.

- **Read-Only Interaction:**  
  All interactions with dark web platforms were observational. No purchases, sales, or communications with illicit actors were conducted.

## 4. Data Collection Methods

- **Manual Exploration:**  
  Navigated forums, marketplaces, and leak sites via verified onion links from trusted OSINT sources and dark web search engines.

- **HTML Snapshots:**  
  Saved representative HTML samples of public pages (e.g., forum posts, ransomware leak listings) for offline analysis.

- **Metadata Extraction:**  
  Extracted timestamps, site uptime, category structures, and visible vendor or group names for research correlation.

## 5. Data Analysis & Documentation

- **Content Classification:**  
  Collected data was categorized into thematic areas: infrastructure, ransomware groups, platforms, scams, OSINT tools, and historical events.

- **Cross-Referencing:**  
  Where possible, dark web findings were cross-referenced with clearnet breach reports, open OSINT databases, and historical archives.

- **Report Compilation:**  
  Notes, screenshots, and HTML samples were organized into Markdown documents, forming the basis of the final **Dark Web Intelligence Report**.

## 6. Ethical & Legal Compliance

- **No Illegal Activity:**  
  All data was gathered passively from open, unprotected sources.

- **Jurisdiction Awareness:**  
  Research was conducted with awareness of applicable cybercrime, privacy, and digital forensics laws.

- **Anonymization:**  
  Any identifiers related to threat actors were anonymized unless they were already widely published by reputable OSINT or law enforcement sources.
